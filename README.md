# Machine Learning Project - kNN Algorithm Implementation

This project involves the implementation of the k-Nearest Neighbors (kNN) algorithm for a classification problem, using the Parzen-window method. 

## Main Tasks

### 1. Implement kNN Algorithm

Implement the kNN algorithm specifically for a classification problem, based on the provided variant. The code should implement the Parzen-window method as covered in the lectures.

### 2. Dataset Exploration

#### a. Tune Parameter 'k'

Experiment with the 'k' parameter in the algorithm and estimate the classification quality metrics. For classification, consider Precision/Recall as the evaluation metrics. More information about these metrics can be found at this [Wikipedia page](https://en.wikipedia.org/wiki/Precision_and_recall#Precision).

#### b. Implement Leave-One-Out (LOO) Algorithm

Implement the Leave-one-out algorithm to find the optimal value for the hyperparameter 'k'. 

#### c. Compare with Scikit-Learn's kNN

For the optimal 'k' value, compare your implementation with the kNN algorithm provided by Scikit-learn. 

For the regression task, visit Scikit-learn's documentation [here](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsRegressor.html#sklearn.neighbors.KNeighborsR).

For the classification task, visit Scikit-learn's documentation [here](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html#sklearn.neighbors.KNeighborsCla).

By following these steps, this project aims to provide a hands-on experience with implementing a common machine learning algorithm, tuning its parameters, and evaluating its performance.
